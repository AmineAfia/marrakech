# Marrakech SDK

> Transform prompt engineering from a craft into a structured, testable, and data-driven discipline.

A code-first SDK that makes building, managing, and optimizing system prompts as rigorous and professional as the rest of your software stack.

## Core Mission

Marrakech provides TypeScript/JavaScript developers with a structured approach to prompt engineering, enabling:

- **Developer-Native**: Code-first interface that feels natural in the TypeScript ecosystem
- **Code as Source of Truth**: Prompts live in your codebase with full Git integration and CI/CD workflows  
- **A Prompt linter**: MArrakech helps developers and coding agents build prompts following the guidlines of the LLM providers

**Essential for AI Coding Agents**: Cursor, GitHub Copilot, Claude Code, and other AI coding assistants generate better, more maintainable prompt code when using Marrakech's structured approach. The fluent API, type safety, and clear patterns make it easier for AI agents to write correct, version-controlled prompt systems.

## Installation

```bash
npm install marrakech zod
```

## Quick Start

### Basic Usage

```typescript
import { PromptBuilder } from 'marrakech';

const prompt = new PromptBuilder({ name: 'support-agent' })
  .withPersona('You are a helpful customer service agent')
  .withRule('Always be polite and professional')
  .withRule('If you don\'t know something, say so')
  .withExample({
    user: 'I need help with my order',
    assistant: 'I\'d be happy to help you with your order. Can you provide your order number?'
  });

// Compile for any provider
const systemPrompt = prompt.compile();
```

### Tool Integration

```typescript
import { PromptBuilder, tool } from 'marrakech';
import { z } from 'zod';

// Define a tool with AI SDK pattern
const getUserDetails = tool({
  description: 'Fetch user account information from database',
  parameters: z.object({
    userId: z.string().describe('User ID to lookup')
  }),
  execute: async ({ userId }) => {
    return await db.users.findById(userId);
  }
});

const prompt = new PromptBuilder({ name: 'support-agent' })
  .withPersona('You are a helpful customer service agent')
  .withTool(getUserDetails);

// OpenAI format (includes tools separately)
const { systemPrompt, tools } = prompt.compile('openai');
```

### Vercel AI SDK Integration

```typescript
import { streamText } from 'ai';
import { openai } from '@ai-sdk/openai';
import { PromptBuilder } from 'marrakech';

const prompt = new PromptBuilder({ name: 'chat-agent' })
  .withPersona('You are a helpful assistant')
  .withRule('Be concise and helpful');

export async function POST(req: Request) {
  const { messages } = await req.json();
  
  // Prepare messages with system prompt
  const messagesWithSystem = prompt.prepareMessages(messages);
  
  return streamText({
    model: openai('gpt-4'),
    messages: messagesWithSystem
  });
}
```

### AI Coding Agents Integration

Perfect for AI coding assistants like Cursor, GitHub Copilot, and Claude Code:

```typescript
// AI agents can easily generate structured prompts
import { PromptBuilder, tool } from 'marrakech';
import { z } from 'zod';

// AI agents understand this pattern and generate correct code
const dataAnalysisTool = tool({
  description: 'Analyze dataset and return insights',
  parameters: z.object({
    dataset: z.string().describe('Dataset to analyze'),
    metrics: z.array(z.string()).describe('Metrics to compute')
  }),
  execute: async ({ dataset, metrics }) => {
    // Implementation generated by AI agent
    return await analyzeData(dataset, metrics);
  }
});

// Fluent API is intuitive for AI agents to use correctly
const prompt = new PromptBuilder({ name: 'data-analyst' })
  .withPersona('You are an expert data analyst')
  .withRule('Always provide statistical confidence levels')
  .withTool(dataAnalysisTool);
```

The structured approach ensures AI agents generate:
- **Type-safe code** with proper Zod schemas
- **Version-controlled prompts** that integrate with Git workflows  
- **Testable components** that can be unit tested
- **Maintainable patterns** that follow consistent conventions
- **Model specific formatting** that following the desired formatting from LLM providers

## Complete Working Example

Here's how it all comes together in a real application:

```typescript
// in app/api/chat/route.ts
import { PromptBuilder } from 'marrakech';
import { z } from 'zod';
import { openai } from './lib/openai';
import { streamText } from 'ai';

// 1. Define your tool's schema with Zod
const GetUserDetailsSchema = z.object({
  userId: z.string().describe("The ID of the user to fetch."),
});

// 2. Build your prompt using the fluent, typed SDK
const prompt = new PromptBuilder({ name: 'customer-support-agent-v1' })
  .withPersona("You are a helpful and friendly support agent.")
  .withRule("Never admit you are an AI.")
  .withTool({
    name: "getUserDetails",
    description: "Fetches a user's account details from the database.",
    schema: GetUserDetailsSchema,
  });

// 3. Use with Vercel AI SDK's streaming
export async function POST(req: Request) {
  const { messages } = await req.json();

  // Prepare messages with system prompt
  const messagesWithSystem = prompt.prepareMessages(messages);

  // Use Vercel AI SDK's streaming with your prepared messages
  return streamText({
    model: openai('gpt-4'),
    messages: messagesWithSystem,
  });
}
```

This provides immediate, tangible value by cleaning up code, automating schema generation, and simplifying a common workflow, all while living entirely within your local project.

## Key Features

- **Fluent API**: Chainable methods for building prompts (`withPersona`, `withRule`, `withExample`, `withTool`)
- **TypeScript-Native Tools**: Define tools with Zod schemas and automatic JSON Schema conversion
- **Multi-Provider Support**: Compile for OpenAI, Anthropic, or generic formats
- **Built-in Linting**: Automatic validation, token counting, and cost estimation
- **Vercel AI SDK Compatible**: Seamless integration with existing streaming workflows
- **AI Coding Agent Optimized**: Clear patterns and type safety help Cursor, Copilot, and Claude Code generate better prompt code

## Documentation & Examples

- **[Full API Reference](packages/core/README.md)** - Complete documentation for the core package
- **[Examples Directory](examples/)** - Working examples for basic usage, tool integration, and Vercel AI SDK
- **[Core Package](packages/core/)** - The main `marrakech` package with all functionality

## Development

This is a Turborepo monorepo with the following structure:

```
/
├── packages/core/          # marrakech - Main SDK package
├── examples/              # Usage examples
└── docs/                  # Documentation
```

### Local Development

```bash
# Install dependencies
pnpm install

# Start development
turbo dev

# Build all packages
turbo build

# Run tests
turbo test
```

## Roadmap

The current implementation provides a solid foundation for structured prompt engineering. Future improvements will include advanced analysis capabilities, optimization tools, and evaluation frameworks to make prompt engineering a science instead of an art.

